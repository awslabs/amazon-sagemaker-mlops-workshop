{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 4/4 - Enabling Monitoring and checking violations\n",
    "\n",
    "In this exercise, we will enable [Model Monitoring](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor.html) for the endpoint we created in the first part. This is an important feature if you need to keep an eye on the your model performance. You check for violations like: invalid input, data drift and more.\n",
    "\n",
    "You start this process by preparing the baseline or a reference set of statistic values that Monitor uses to compare with the payload and identify anomalies.  \n",
    "\n",
    "There is a cron job like called Monitoring Schedulle. This element will keep processing the logs (in and out) to create the reports you can see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import numpy as np\n",
    "import boto3\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "role = get_execution_role()\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "dataset = np.insert(X, 0, y,axis=1)\n",
    "pd.DataFrame(data=dataset, columns=['iris_id'] + iris.feature_names).to_csv('full_dataset.csv', index=None)\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "prefix='mlops/iris'\n",
    "endpoint_name = open('endpoint_name.txt', 'r').read().strip() if os.path.isfile('endpoint_name.txt') else None\n",
    "endpoint_name2 = open('endpoint_name2.txt', 'r').read().strip() if os.path.isfile('endpoint_name2.txt') else None\n",
    "\n",
    "try:\n",
    "    xgb_predictor = sagemaker.predictor.Predictor(endpoint_name=endpoint_name, sagemaker_session=sagemaker_session)\n",
    "    xgb_predictor.serializer = CSVSerializer()\n",
    "except Exception as e:\n",
    "    raise Exception(\"You must run Part 1 before this. There, you will train/deploy a Model and use it here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import DefaultModelMonitor\n",
    "from sagemaker.model_monitor.dataset_format import DatasetFormat\n",
    "\n",
    "endpoint_monitor = DefaultModelMonitor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    volume_size_in_gb=20,\n",
    "    max_runtime_in_seconds=3600,\n",
    ")\n",
    "endpoint_monitor.suggest_baseline(\n",
    "    baseline_dataset='full_dataset.csv',\n",
    "    dataset_format=DatasetFormat.csv(header=True),\n",
    "    output_s3_uri='s3://{}/{}/monitoring/baseline'.format(bucket, prefix),\n",
    "    wait=True,\n",
    "    logs=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just take a look on the baseline created/suggested by SageMaker for your dataset\n",
    "This set of statistics and constraints will be used by the Monitoring Scheduler to compare the incoming data with what is considered **normal**. Each invalid payload sent to the endpoint will be considered a violation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_job = endpoint_monitor.latest_baselining_job\n",
    "schema_df = pd.json_normalize(baseline_job.baseline_statistics().body_dict[\"features\"])\n",
    "constraints_df = pd.json_normalize(baseline_job.suggested_constraints().body_dict[\"features\"])\n",
    "report_df = schema_df.merge(constraints_df)\n",
    "report_df.drop([\n",
    "    'numerical_statistics.distribution.kll.buckets',\n",
    "    'numerical_statistics.distribution.kll.sketch.data',\n",
    "    'numerical_statistics.distribution.kll.sketch.parameters.c'\n",
    "], axis=1).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then, we need to create a **Monitoring Schedule** for our endpoint. The command below will create a cron scheduler that will process the log each hour, then we can see how well our model is going."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import CronExpressionGenerator\n",
    "from time import gmtime, strftime\n",
    "\n",
    "endpoint_monitor.create_monitoring_schedule(\n",
    "    endpoint_input=endpoint_name,\n",
    "    output_s3_uri='s3://{}/{}/monitoring/reports'.format(bucket, prefix),\n",
    "    statistics=endpoint_monitor.baseline_statistics(),\n",
    "    constraints=endpoint_monitor.suggested_constraints(),\n",
    "    schedule_cron_expression=CronExpressionGenerator.hourly(),\n",
    "    enable_cloudwatch_metrics=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how you can list all the monitoring schedules you created in your account\n",
    "!aws sagemaker list-monitoring-schedules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start generating some artificial traffic\n",
    "The cell below starts a thread to send some traffic to the endpoint. Note that you need to stop the kernel to terminate this thread. If there is no traffic, the monitoring jobs are marked as `Failed` since there is no data to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time \n",
    "from threading import Thread\n",
    "\n",
    "traffic_generator_running=True\n",
    "def invoke_endpoint_forever():\n",
    "    print('Invoking endpoint forever!')\n",
    "    while traffic_generator_running:\n",
    "        ## This will create an invalid set of features\n",
    "        ## The idea is to violate two monitoring constraings: not_null and data_drift\n",
    "        null_idx = random.randint(0,3)\n",
    "        sample = [random.randint(500,2000) / 100.0 for i in range(4)]\n",
    "        sample[null_idx] = None\n",
    "        xgb_predictor.predict(sample)\n",
    "        time.sleep(0.5)\n",
    "    print('Endpoint invoker has stopped')\n",
    "Thread(target = invoke_endpoint_forever).start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kick off a processing job to analyze the logs\n",
    "Since the Monitoring Scheduler will only run each full hour and we don't have that time to wait, let's kick off a processin job manually (that simulates what the scheduler does) and see the report with the violations our Thread above will cause to the endpoint with the random payload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import boto3\n",
    "\n",
    "def process_monitoring_logs(endpoint_monitor):\n",
    "    sm = boto3.client('sagemaker')\n",
    "    now = datetime.datetime.today()\n",
    "    suffix = now.strftime(\"%Y/%m/%d/%H\")\n",
    "    start_time = datetime.datetime(now.year, now.month, now.day, now.hour)\n",
    "    end_time = start_time + datetime.timedelta(hours=1)\n",
    "\n",
    "    # get the monitoring metadata\n",
    "    base_desc = endpoint_monitor.describe_latest_baselining_job()\n",
    "    sche_desc = endpoint_monitor.describe_schedule()\n",
    "    baseline_path = base_desc['ProcessingOutputConfig']['Outputs'][0]['S3Output']['S3Uri']\n",
    "    endpoint_name = sche_desc['EndpointName']\n",
    "\n",
    "    variant_name = sm.describe_endpoint(EndpointName=endpoint_name)['ProductionVariants'][0]['VariantName']\n",
    "    logs_path = \"%s/%s/%s\" % (endpoint_name,variant_name,suffix)\n",
    "    \n",
    "    s3_output = {\n",
    "        \"S3Uri\": 's3://{}/{}/monitoring/{}'.format(bucket, prefix, logs_path),\n",
    "        \"LocalPath\": \"/opt/ml/processing/output\",\n",
    "        \"S3UploadMode\": \"Continuous\"\n",
    "    }\n",
    "    # values for the processing job input\n",
    "    values = [\n",
    "        [ 'input_1', 's3://{}/{}/monitoring/{}'.format(bucket, prefix, logs_path),\n",
    "            '/opt/ml/processing/input/endpoint/{}'.format(logs_path) ], \n",
    "        [ 'baseline', '%s/statistics.json' % baseline_path,\n",
    "            '/opt/ml/processing/baseline/stats'],\n",
    "        [ 'constraints', '%s/constraints.json' % baseline_path,\n",
    "            '/opt/ml/processing/baseline/constraints']\n",
    "    ]\n",
    "    job_params = {\n",
    "        'ProcessingJobName': 'model-monitoring-%s' % time.strftime(\"%Y%m%d%H%M%S\"),\n",
    "        'ProcessingInputs': [{\n",
    "            'InputName': o[0],\n",
    "            'S3Input': { \n",
    "                'S3Uri': o[1], 'LocalPath': o[2], 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', \n",
    "                'S3CompressionType': 'None', 'S3DataDistributionType': 'FullyReplicated'\n",
    "            }} for o in values],\n",
    "        'ProcessingOutputConfig': { 'Outputs': [ {'OutputName': 'result','S3Output': s3_output } ] },\n",
    "        'ProcessingResources': base_desc['ProcessingResources'],\n",
    "        'AppSpecification': base_desc['AppSpecification'],\n",
    "        'RoleArn': base_desc['RoleArn'],\n",
    "        'Environment': {\n",
    "            'baseline_constraints': '/opt/ml/processing/baseline/constraints/constraints.json',\n",
    "            'baseline_statistics': '/opt/ml/processing/baseline/stats/statistics.json',\n",
    "            'dataset_format': '{\"sagemakerCaptureJson\":{\"captureIndexNames\":[\"endpointInput\",\"endpointOutput\"]}}',\n",
    "            'dataset_source': '/opt/ml/processing/input/endpoint',      \n",
    "            'output_path': '/opt/ml/processing/output',\n",
    "            'publish_cloudwatch_metrics': 'Enabled',\n",
    "            'sagemaker_monitoring_schedule_name': sche_desc['MonitoringScheduleName'],\n",
    "            'sagemaker_endpoint_name': endpoint_name,\n",
    "            'start_time': start_time.strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "            'end_time': end_time.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "        }\n",
    "    }\n",
    "    sm.create_processing_job(**job_params)\n",
    "    waiter = sm.get_waiter('processing_job_completed_or_stopped')\n",
    "    waiter.wait( ProcessingJobName=job_params['ProcessingJobName'], WaiterConfig={'Delay': 30,'MaxAttempts': 20} )\n",
    "    return job_params['ProcessingJobName'], s3_output['S3Uri']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "## The processing job takes something like 5mins to run\n",
    "job_name, s3_output = process_monitoring_logs(endpoint_monitor)\n",
    "tokens = s3_output.split('/', 3)\n",
    "df = pd.read_json(sagemaker_session.read_s3_file(tokens[2], '%s/constraint_violations.json' % tokens[3]))\n",
    "df = pd.json_normalize(df.violations)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also check these metrics on CloudWatch. Just open the CloudWatch console, click on **Metrics**, then select:\n",
    "    All -> aws/sagemaker/Endpoints/data-metrics -> Endpoint, MonitoringSchedule\n",
    "\n",
    "Use the *endpoint_monitor* name to filter the metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_generator_running=False\n",
    "time.sleep(3)\n",
    "endpoint_monitor.delete_monitoring_schedule()\n",
    "time.sleep(10) # wait for 10 seconds before trying to delete the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    xgb_predictor = sagemaker.predictor.Predictor(endpoint_name=endpoint_name, sagemaker_session=sagemaker_session)\n",
    "    xgb_predictor.delete_endpoint()\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "try:\n",
    "    xgb_predictor2 = sagemaker.predictor.Predictor(endpoint_name=endpoint_name2, sagemaker_session=sagemaker_session)\n",
    "    xgb_predictor2.delete_endpoint()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
