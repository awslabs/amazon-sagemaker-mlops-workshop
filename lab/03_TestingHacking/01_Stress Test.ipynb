{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stress Test\n",
    "\n",
    "The idea of this code is to see how the production Endpoint will behave when a **bunch** of requests arrive it.\n",
    "Let's simulate several users doing predictions at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import boto3\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = boto3.client(\"sagemaker-runtime\")\n",
    "codepipeline = boto3.client('codepipeline')\n",
    "\n",
    "pipeline_name = 'iris-model-pipeline'\n",
    "endpoint_name_mask='mlops-iris-model-%s-%s'\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "dataset = np.insert(iris.data, 0, iris.target,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_env_jobid(env):\n",
    "    response = codepipeline.get_pipeline_state( name=pipeline_name )\n",
    "    for stage in response['stageStates']:\n",
    "        if stage['stageName'] == 'Deploy%s' % env.capitalize():\n",
    "            for action in stage['actionStates']:\n",
    "                if action['actionName'] == 'DeployModel%s' % env.capitalize():\n",
    "                    return stage['latestExecution']['pipelineExecutionId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(payload):\n",
    "    payload = payload\n",
    "    X = [ payload[1:] ]\n",
    "    y = payload[0]\n",
    "    response = []\n",
    "    elapsed_time = time.time()\n",
    "    resp = sm.invoke_endpoint(\n",
    "        EndpointName=endpoint_name_mask % (env, job_id),\n",
    "        CustomAttributes='logistic',\n",
    "        Body=json.dumps(X)\n",
    "    )\n",
    "    elapsed_time = time.time() - elapsed_time\n",
    "    resp = json.loads(resp['Body'].read())\n",
    "    response.append((resp['iris_id'][0] == y, elapsed_time))\n",
    "    \n",
    "    elapsed_time = time.time()\n",
    "    resp = sm.invoke_endpoint(\n",
    "        EndpointName=endpoint_name_mask % (env, job_id),\n",
    "        CustomAttributes='random_forest',\n",
    "        Body=json.dumps(X)\n",
    "    )\n",
    "    elapsed_time = time.time() - elapsed_time\n",
    "    resp = json.loads(resp['Body'].read())\n",
    "    response.append((resp['iris_id'][0] == y, elapsed_time))\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test(max_threads, max_requests):\n",
    "    num_batches = math.ceil(max_requests / len(dataset))\n",
    "    requests = []\n",
    "    for i in range(num_batches):\n",
    "        batch = dataset.copy()\n",
    "        np.random.shuffle(batch)\n",
    "        requests += batch.tolist()\n",
    "    len(requests)\n",
    "\n",
    "    pool = ThreadPool(max_threads)\n",
    "    result = pool.map(predict, requests)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    correct_logistic=0\n",
    "    correct_random_forest=0\n",
    "    elapsedtime_logistic=0\n",
    "    elapsedtime_random_forest=0\n",
    "    for i in result:\n",
    "        correct_logistic += i[0][0]\n",
    "        correct_random_forest += i[1][0]\n",
    "\n",
    "        elapsedtime_logistic += i[0][1]\n",
    "        elapsedtime_random_forest += i[1][1]\n",
    "    print(\"Score logistic: {}\".format(correct_logistic/len(result)))\n",
    "    print(\"Score random forest: {}\".format(correct_random_forest/len(result)))\n",
    "\n",
    "    print(\"Elapsed time logistic: {}s\".format(elapsedtime_logistic))\n",
    "    print(\"Elapsed time random forest: {}s\".format(elapsedtime_random_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env='prd'\n",
    "job_id=get_env_jobid(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"Starting test 1\")\n",
    "run_test(10, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"Starting test 2\")\n",
    "run_test(100, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"Starting test 3\")\n",
    "run_test(150, 100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> While this test is running, go to the **AWS Console** -> **Sagemaker**, then click on the **Endpoint** and then click on the **CloudWatch** monitoring logs to see the Endpoint Behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In CloudWatch, mark the following three checkboxes\n",
    "![CloudWatchA](../../imgs/CloudWatchA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Then, change the following config, marked in RED\n",
    "\n",
    "![CloudWatchB](../../imgs/CloudWatchB.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, while your stress test is still running, you will see the Auto Scaling Alarm like this, after 3 datapoints above 750 Invocations Per Instance\n",
    "\n",
    "![CloudWatchC](../../imgs/CloudWatchC.png)\n",
    "\n",
    "When this happens, the Endpoint Autoscaling will start adding more instances to your cluster. You can observe in the Graph from the previous image that, after new instances are added to the cluster, the **Invocations** metrics grows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Well done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
